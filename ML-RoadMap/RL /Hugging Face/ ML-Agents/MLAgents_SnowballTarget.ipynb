{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMh7OUvXIDnAtAXtBaFAhqC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dogukartal/ML-RoadMap/blob/main/ML-RoadMap/RL%20/Hugging%20Face/%20ML-Agents/MLAgents_SnowballTarget.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bo70QL2OQS8"
      },
      "outputs": [],
      "source": [
        "!git clone --depth 1 https://github.com/Unity-Technologies/ml-agents\n",
        "%cd ml-agents\n",
        "!pip install -e ./ml-agents-envs\n",
        "!pip install -e ./ml-agents\n",
        "\n",
        "!mkdir ./training-envs-executables\n",
        "!mkdir ./training-envs-executables/linux\n",
        "!wget \"https://github.com/huggingface/Snowball-Target/raw/main/SnowballTarget.zip\" -O ./training-envs-executables/linux/SnowballTarget.zip\n",
        "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/SnowballTarget.zip\n",
        "!chmod -R 755 ./training-envs-executables/linux/SnowballTarget"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML-Agents: https://github.com/Unity-Technologies/ml-agents/blob/release_20_docs/docs/Training-Configuration-File.md\n",
        "\n",
        "Hyperparamters: ./content/ml-agents/config/ppo/"
      ],
      "metadata": {
        "id": "zX2STwp2Qa9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./ml-agents/mlagents/trainers/learn.py ./config/ppo/SnowballTarget.yaml --env=./training-envs-executables/linux/SnowballTarget/SnowballTarget --run-id=\"SnowballTarget1\" --no-graphics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0tiL31kQYmQ",
        "outputId": "7da78b51-408e-4700-95c9-22bd66369154"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:431.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "2024-07-25 09:54:28.375455: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-25 09:54:28.375504: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-25 09:54:28.489829: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-25 09:54:28.707479: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-25 09:54:30.621814: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "            ┐  ╖\n",
            "        ╓╖╬│╡  ││╬╖╖\n",
            "    ╓╖╬│││││┘  ╬│││││╬╖\n",
            " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
            " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
            " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
            " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
            " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
            " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
            " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
            "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
            "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
            "          ╙╬╬╬╣╣╣╜\n",
            "             ╙\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 1.1.0.dev0,\n",
            "  ml-agents-envs: 1.1.0.dev0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 2.3.1+cu121\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
            "[INFO] Connected new brain: SnowballTarget?team=0\n",
            "[INFO] Hyperparameters for behavior name SnowballTarget: \n",
            "\ttrainer_type:\tppo\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t128\n",
            "\t  buffer_size:\t2048\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.005\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  shared_critic:\tFalse\n",
            "\t  learning_rate_schedule:\tlinear\n",
            "\t  beta_schedule:\tlinear\n",
            "\t  epsilon_schedule:\tlinear\n",
            "\tcheckpoint_interval:\t50000\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t256\n",
            "\t  num_layers:\t2\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t10\n",
            "\teven_checkpoints:\tFalse\n",
            "\tmax_steps:\t200000\n",
            "\ttime_horizon:\t64\n",
            "\tsummary_freq:\t10000\n",
            "\tthreaded:\tTrue\n",
            "\tself_play:\tNone\n",
            "\tbehavioral_cloning:\tNone\n",
            "[INFO] SnowballTarget. Step: 10000. Time Elapsed: 27.382 s. Mean Reward: 3.000. Std of Reward: 2.226. Training.\n",
            "[INFO] SnowballTarget. Step: 20000. Time Elapsed: 51.178 s. Mean Reward: 6.182. Std of Reward: 2.855. Training.\n",
            "[INFO] SnowballTarget. Step: 30000. Time Elapsed: 72.339 s. Mean Reward: 8.682. Std of Reward: 2.438. Training.\n",
            "[INFO] SnowballTarget. Step: 40000. Time Elapsed: 96.693 s. Mean Reward: 10.836. Std of Reward: 2.768. Training.\n",
            "[INFO] SnowballTarget. Step: 50000. Time Elapsed: 119.804 s. Mean Reward: 13.727. Std of Reward: 2.368. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-49936.onnx\n",
            "[INFO] SnowballTarget. Step: 60000. Time Elapsed: 142.856 s. Mean Reward: 14.745. Std of Reward: 2.546. Training.\n",
            "[INFO] SnowballTarget. Step: 70000. Time Elapsed: 166.002 s. Mean Reward: 16.068. Std of Reward: 2.666. Training.\n",
            "[INFO] SnowballTarget. Step: 80000. Time Elapsed: 189.531 s. Mean Reward: 18.218. Std of Reward: 2.513. Training.\n",
            "[INFO] SnowballTarget. Step: 90000. Time Elapsed: 210.391 s. Mean Reward: 19.295. Std of Reward: 2.528. Training.\n",
            "[INFO] SnowballTarget. Step: 100000. Time Elapsed: 233.981 s. Mean Reward: 20.109. Std of Reward: 2.563. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-99960.onnx\n",
            "[INFO] SnowballTarget. Step: 110000. Time Elapsed: 257.812 s. Mean Reward: 21.611. Std of Reward: 2.206. Training.\n",
            "[INFO] SnowballTarget. Step: 120000. Time Elapsed: 279.687 s. Mean Reward: 20.911. Std of Reward: 2.074. Training.\n",
            "[INFO] SnowballTarget. Step: 130000. Time Elapsed: 302.513 s. Mean Reward: 22.509. Std of Reward: 2.536. Training.\n",
            "[INFO] SnowballTarget. Step: 140000. Time Elapsed: 324.358 s. Mean Reward: 23.295. Std of Reward: 1.914. Training.\n",
            "[INFO] SnowballTarget. Step: 150000. Time Elapsed: 347.789 s. Mean Reward: 24.073. Std of Reward: 2.522. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-149984.onnx\n",
            "[INFO] SnowballTarget. Step: 160000. Time Elapsed: 369.595 s. Mean Reward: 24.477. Std of Reward: 1.983. Training.\n",
            "[INFO] SnowballTarget. Step: 170000. Time Elapsed: 392.349 s. Mean Reward: 25.018. Std of Reward: 2.720. Training.\n",
            "[INFO] SnowballTarget. Step: 180000. Time Elapsed: 414.697 s. Mean Reward: 24.932. Std of Reward: 2.499. Training.\n",
            "[INFO] SnowballTarget. Step: 190000. Time Elapsed: 440.243 s. Mean Reward: 25.127. Std of Reward: 2.405. Training.\n",
            "[INFO] SnowballTarget. Step: 200000. Time Elapsed: 461.801 s. Mean Reward: 25.773. Std of Reward: 2.255. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-199984.onnx\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-200112.onnx\n",
            "[INFO] Copied results/SnowballTarget1/SnowballTarget/SnowballTarget-200112.onnx to results/SnowballTarget1/SnowballTarget.onnx.\n"
          ]
        }
      ]
    }
  ]
}